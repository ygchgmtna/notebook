
# PyTorch `nn.Linear()` å…¨é¢ä»‹ç»

ä¸‹é¢æ˜¯å¯¹ `nn.Linear()` çš„è¯¦ç»†ä»‹ç»ï¼Œæ¶µç›–å…¶ **ä½œç”¨ã€å‚æ•°ã€åŸç†ã€ç¤ºä¾‹ã€åˆå§‹åŒ–æœºåˆ¶ã€ä¸ Conv2d çš„å…³ç³»** ç­‰å†…å®¹ã€‚

---

## âœ… ä¸€ã€`nn.Linear()` æ˜¯ä»€ä¹ˆï¼Ÿ

`nn.Linear()` æ˜¯ PyTorch ä¸­ç”¨äºå®šä¹‰ **å…¨è¿æ¥å±‚ï¼ˆFully Connected Layerï¼‰** æˆ–ç§° **çº¿æ€§å±‚** çš„å‡½æ•°ã€‚

å®ƒå®ç°äº†å¦‚ä¸‹çš„çº¿æ€§å˜æ¢ï¼š

```math
\text{output} = x \cdot W^T + b
```

- \( x \)ï¼šè¾“å…¥å¼ é‡ï¼Œå½¢çŠ¶ä¸º `(batch_size, in_features)`
- \( W \)ï¼šæƒé‡çŸ©é˜µï¼Œå½¢çŠ¶ä¸º `(out_features, in_features)`
- \( b \)ï¼šåç½®é¡¹ï¼Œå½¢çŠ¶ä¸º `(out_features,)`

---

## ğŸ”§ äºŒã€å‡½æ•°å®šä¹‰ä¸å‚æ•°

```python
torch.nn.Linear(in_features, out_features, bias=True)
```

| å‚æ•°           | è¯´æ˜                                     |
|----------------|------------------------------------------|
| `in_features`  | è¾“å…¥ç‰¹å¾æ•°ï¼ˆè¾“å…¥å¼ é‡çš„æœ€åä¸€ç»´å¤§å°ï¼‰     |
| `out_features` | è¾“å‡ºç‰¹å¾æ•°ï¼ˆçº¿æ€§å±‚çš„è¾“å‡ºå¤§å°ï¼‰           |
| `bias`         | æ˜¯å¦åŒ…å«åç½®é¡¹ï¼Œé»˜è®¤ä¸º `True`            |

---

## ğŸ“¦ ä¸‰ã€æƒé‡å’Œåç½®

åˆ›å»º `nn.Linear` å±‚åï¼Œè‡ªåŠ¨åŒ…å«ï¼š

- `weight`: `[out_features, in_features]`
- `bias`: `[out_features]`ï¼ˆè‹¥è®¾ç½®ä¸º `True`ï¼‰

```python
linear = nn.Linear(3, 2)
print(linear.weight.shape)  # torch.Size([2, 3])
print(linear.bias.shape)    # torch.Size([2])
```

---

## ğŸ§  å››ã€å·¥ä½œåŸç†ï¼ˆforwardè¿‡ç¨‹ï¼‰

```python
output = input @ weight.T + bias
```

å…¶ä¸­ `@` è¡¨ç¤ºçŸ©é˜µä¹˜æ³•ã€‚

---

## ğŸ“˜ äº”ã€ç®€å•ç¤ºä¾‹

```python
import torch
import torch.nn as nn

fc = nn.Linear(3, 2)
x = torch.tensor([[1.0, 2.0, 3.0]])
y = fc(x)
print(y)  # shape: (1, 2)
```

---

## ğŸ” å…­ã€å¸¸è§åº”ç”¨åœºæ™¯

| åœºæ™¯                   | ç”¨æ³•                                 |
|------------------------|--------------------------------------|
| ç¥ç»ç½‘ç»œåˆ†ç±»å™¨çš„è¾“å‡ºå±‚ | `nn.Linear(hidden_dim, num_classes)` |
| Transformer çš„ Q/K/V  | `nn.Linear(embed_dim, head_dim)`     |
| ç¼–ç ç‰¹å¾æ˜ å°„           | æ”¹å˜ç»´åº¦ï¼Œå¦‚ `nn.Linear(768, 256)`    |

---

## ğŸ§ª ä¸ƒã€æ˜¯å¦å¸¦åç½®çš„åŒºåˆ«

```python
nn.Linear(128, 64, bias=True)
nn.Linear(128, 64, bias=False)
```

ä¸åŠ åç½®å¸¸ç”¨äºæ­é… BatchNorm å±‚ï¼Œä»¥é¿å…å‚æ•°å†—ä½™ã€‚

---

## ğŸ§° å…«ã€é…åˆæ¿€æ´»å‡½æ•°ä½¿ç”¨

çº¿æ€§å±‚æœ¬èº«ä¸åŒ…å«æ¿€æ´»å‡½æ•°ï¼Œé€šå¸¸æ­é…ä½¿ç”¨ï¼š

```python
model = nn.Sequential(
    nn.Linear(128, 64),
    nn.ReLU(),
    nn.Linear(64, 10)
)
```

---

## ğŸ§¬ ä¹ã€æŸ¥çœ‹æƒé‡å’Œæ¢¯åº¦

```python
fc = nn.Linear(3, 2)
out = fc(torch.randn(1, 3))
loss = out.sum()
loss.backward()

print(fc.weight.data)
print(fc.weight.grad)
```

---

## âœ… åã€æ€»ç»“

| ç‚¹ä½     | è¯´æ˜                              |
|----------|-----------------------------------|
| æœ¬è´¨     | çº¿æ€§æ˜ å°„ `y = xW^T + b`           |
| åº”ç”¨     | åˆ†ç±»å™¨ã€æ³¨æ„åŠ›æŠ•å½±ã€ç‰¹å¾å˜æ¢ç­‰    |
| å‚æ•°     | `in_features`, `out_features`, `bias` |
| é…åˆä½¿ç”¨ | ä¸æ¿€æ´»å‡½æ•°ã€BatchNorm æ­é…ä½¿ç”¨   |

---

å¦‚éœ€äº†è§£å…¶æºç æœºåˆ¶ã€åˆå§‹åŒ–ç»†èŠ‚æˆ–ä¸ `Conv2d` çš„åŒºåˆ«ï¼Œè¯·å‚è€ƒå¦ä¸€ç¯‡æ·±å…¥è®²è§£ã€‚
